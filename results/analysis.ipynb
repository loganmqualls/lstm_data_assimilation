{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATE_NEW_METRICS = True\n",
    "filename = 'all_statistics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralhydrology.evaluation import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NSE',\n",
       " 'KGE',\n",
       " 'Alpha-NSE',\n",
       " 'Pearson-r',\n",
       " 'Beta-NSE',\n",
       " 'Peak-Timing-Error',\n",
       " 'Peak-Timing-Abs-Error',\n",
       " 'Missed-Peaks',\n",
       " 'Peak-Abs-Bias']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_list = metrics.get_available_metrics()\n",
    "metrics_list.remove('MSE')\n",
    "metrics_list.remove('RMSE')\n",
    "metrics_list.remove('FHV')\n",
    "metrics_list.remove('FMS')\n",
    "metrics_list.remove('FLV')\n",
    "metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_file = '../531_basin_list.txt'\n",
    "autoregression_50_holdout_dir = '../runs/autoregression_50_holdout/test'\n",
    "autoregression_holdout_dir = '../runs/autoregression_holdout/test'\n",
    "autoregression_noholdout_dir = '../runs/autoregression_noholdout/test'\n",
    "assimilation_dir = '../runs/simulation/assimilation/'\n",
    "simulation_dir = '../runs/simulation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 531 basins.\n"
     ]
    }
   ],
   "source": [
    "with Path(basin_file).open('r') as fp:\n",
    "    basins = sorted(basin.strip() for basin in fp if basin.strip())\n",
    "print(f\"There are {len(basins)} basins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 simulation runs.\n"
     ]
    }
   ],
   "source": [
    "simulation_run_dirs = glob.glob(simulation_dir + '/simulation_*')\n",
    "for i, run_dir in enumerate(simulation_run_dirs):\n",
    "    simulation_run_dirs[i] = run_dir.split('/')[-1]\n",
    "print(f\"There are {len(simulation_run_dirs)} simulation runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 assimilation runs.\n"
     ]
    }
   ],
   "source": [
    "assimilation_run_dirs = glob.glob(assimilation_dir + '/**')\n",
    "for i, run_dir in enumerate(assimilation_run_dirs):\n",
    "    assimilation_run_dirs[i] = run_dir.split('/')[-1]\n",
    "print(f\"There are {len(assimilation_run_dirs)} assimilation runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 no-holdout autoregression runs.\n"
     ]
    }
   ],
   "source": [
    "autoregression_noholdout_run_dirs = glob.glob(autoregression_noholdout_dir + '/**')\n",
    "for i, run_dir in enumerate(autoregression_noholdout_run_dirs):\n",
    "    autoregression_noholdout_run_dirs[i] = run_dir.split('/')[-1]\n",
    "print(f\"There are {len(autoregression_noholdout_run_dirs)} no-holdout autoregression runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 50% holdout autoregression runs.\n"
     ]
    }
   ],
   "source": [
    "autoregression_50_holdout_run_dirs = glob.glob(autoregression_50_holdout_dir + '/**')\n",
    "for i, run_dir in enumerate(autoregression_50_holdout_run_dirs):\n",
    "    autoregression_50_holdout_run_dirs[i] = run_dir.split('/')[-1]\n",
    "print(f\"There are {len(autoregression_50_holdout_run_dirs)} 50% holdout autoregression runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 variable fraction holdout autoregression runs.\n"
     ]
    }
   ],
   "source": [
    "autoregression_holdout_run_dirs = glob.glob(autoregression_holdout_dir + '/**')\n",
    "for i, run_dir in enumerate(autoregression_holdout_run_dirs):\n",
    "    autoregression_holdout_run_dirs[i] = run_dir.split('/')[-1]\n",
    "print(f\"There are {len(autoregression_holdout_run_dirs)} variable fraction holdout autoregression runs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_times = []\n",
    "holdout_fractions = []\n",
    "ensembles = []\n",
    "for run in autoregression_50_holdout_run_dirs:\n",
    "    holdout_fractions.append(float(run.split('_')[0]))    \n",
    "    lead_times.append(int(run.split('_')[1]))  \n",
    "    ensembles.append(int(run.split('_')[2]))\n",
    "\n",
    "holdout_fractions = sorted(list(set(holdout_fractions)))\n",
    "lead_times = sorted(list(set(lead_times)))\n",
    "ensembles = sorted(list(set(ensembles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_index = pd.MultiIndex.from_product((holdout_fractions, lead_times, ensembles))\n",
    "fracs_index = pd.MultiIndex.from_product((holdout_fractions, holdout_fractions, ensembles))\n",
    "\n",
    "autoregression_holdout_statistics = {}\n",
    "autoregression_noholdout_statistics = {}\n",
    "autoregression_fractional_holdout_statistics = {}\n",
    "assimilation_statistics = {}\n",
    "simulation_statistics = {}\n",
    "\n",
    "for metric in metrics_list:\n",
    "    autoregression_fractional_holdout_statistics[metric] = pd.DataFrame(index=basins, \n",
    "                                                                        columns=fracs_index,\n",
    "                                                                        dtype=np.float64)\n",
    "\n",
    "    autoregression_holdout_statistics[metric] = pd.DataFrame(index=basins, \n",
    "                                                             columns=run_index,\n",
    "                                                             dtype=np.float64)\n",
    "    autoregression_noholdout_statistics[metric] = pd.DataFrame(index=basins, \n",
    "                                                               columns=run_index,\n",
    "                                                               dtype=np.float64)\n",
    "    assimilation_statistics[metric] = pd.DataFrame(index=basins, \n",
    "                                                   columns=run_index,\n",
    "                                                   dtype=np.float64)\n",
    "    assimilation_statistics[metric] = pd.DataFrame(index=basins, \n",
    "                                                   columns=run_index,\n",
    "                                                   dtype=np.float64)\n",
    "    simulation_statistics[metric] = pd.DataFrame(index=basins, \n",
    "                                                 columns=run_index,\n",
    "                                                 dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr = {}\n",
    "for run in assimilation_run_dirs:\n",
    "    hf = float(run.split('_')[0])   \n",
    "    if hf == 0.0:\n",
    "        try:\n",
    "            with open(assimilation_dir + '/' + run + '/test/model_epoch030/test_results.p', 'rb') as f:\n",
    "                run_data = pkl.load(f)\n",
    "            for basin in basins:\n",
    "                xr[basin] = run_data[basin]['1D']['xr']['QObs(mm/d)_obs']\n",
    "            break\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALCULATE_NEW_METRICS:\n",
    "    for run in simulation_run_dirs:\n",
    "\n",
    "        en = int(run.split('_')[1])\n",
    "        with open(simulation_dir + '/' + run + '/test/model_epoch030/test_results.p', 'rb') as f:\n",
    "            run_data = pkl.load(f)\n",
    "\n",
    "        for basin in basins:\n",
    "\n",
    "            sim = run_data[basin]['1D']['xr'].stack(datetime=['date', 'time_step'])['QObs(mm/d)_sim']\n",
    "            sim['datetime'] = sim.coords['date']# + sim.coords['time_step']\n",
    "            obs = xr[basin].stack(datetime=['date', 'time_step'])\n",
    "            obs['datetime'] = obs.coords['date']# + obs.coords['time_step']\n",
    "            basin_metrics = metrics.calculate_metrics(obs=obs, sim=sim, metrics=metrics_list)\n",
    "\n",
    "            for metric in metrics_list:\n",
    "                simulation_statistics[metric].loc[basin, (0, 1, en)] = basin_metrics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6c8416eb3c4d0c9279bdaf82a8e559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CALCULATE_NEW_METRICS:\n",
    "    for run in tqdm(autoregression_50_holdout_run_dirs):\n",
    "        hf = float(run.split('_')[0])   \n",
    "        lt = int(run.split('_')[1])\n",
    "        en = int(run.split('_')[2])\n",
    "\n",
    "        with open(autoregression_50_holdout_dir + '/' + run + '/test/model_epoch030/test_results.p', 'rb') as f:\n",
    "            run_data = pkl.load(f)\n",
    "\n",
    "        for basin in basins:\n",
    "            sim = run_data[basin]['1D']['xr'].stack(datetime=['date', 'time_step'])['QObs(mm/d)_sim']\n",
    "            sim['datetime'] = sim.coords['date']# + sim.coords['time_step']\n",
    "            obs = xr[basin].stack(datetime=['date', 'time_step'])\n",
    "            obs['datetime'] = obs.coords['date']# + obs.coords['time_step']\n",
    "            basin_metrics = metrics.calculate_metrics(obs=obs, sim=sim, metrics=metrics_list)\n",
    "\n",
    "            for metric in metrics_list:\n",
    "                autoregression_holdout_statistics[metric].loc[basin, (hf, lt, en)] = basin_metrics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c05f2658ce4cce84f0562232f93a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CALCULATE_NEW_METRICS:\n",
    "    for run in tqdm(autoregression_noholdout_run_dirs):\n",
    "        hf = float(run.split('_')[0])   \n",
    "        lt = int(run.split('_')[1])\n",
    "        en = int(run.split('_')[2])\n",
    "\n",
    "        with open(autoregression_noholdout_dir + '/' + run + '/test/model_epoch030/test_results.p', 'rb') as f:\n",
    "            run_data = pkl.load(f)\n",
    "\n",
    "        for basin in basins:\n",
    "            sim = run_data[basin]['1D']['xr'].stack(datetime=['date', 'time_step'])['QObs(mm/d)_sim']\n",
    "            sim['datetime'] = sim.coords['date']# + sim.coords['time_step']\n",
    "            obs = xr[basin].stack(datetime=['date', 'time_step'])\n",
    "            obs['datetime'] = obs.coords['date']# + obs.coords['time_step']\n",
    "            basin_metrics = metrics.calculate_metrics(obs=obs, sim=sim, metrics=metrics_list)\n",
    "\n",
    "            for metric in metrics_list:\n",
    "                autoregression_noholdout_statistics[metric].loc[basin, (hf, lt, en)] = basin_metrics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9611feb63575428ab6ccf361b2cbeda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CALCULATE_NEW_METRICS:\n",
    "    for run in tqdm(assimilation_run_dirs):\n",
    "        hf = float(run.split('_')[0])   \n",
    "        lt = int(run.split('_')[1])\n",
    "        en = int(run.split('_')[2])\n",
    "        with open(assimilation_dir + '/' + run + '/test/model_epoch030/test_results.p', 'rb') as f:\n",
    "            run_data = pkl.load(f)\n",
    "\n",
    "        for basin in basins:\n",
    "            sim = run_data[basin]['1D']['xr'].stack(datetime=['date', 'time_step'])['QObs(mm/d)_sim']\n",
    "            sim['datetime'] = sim.coords['date']# + sim.coords['time_step']\n",
    "            obs = xr[basin].stack(datetime=['date', 'time_step'])\n",
    "            obs['datetime'] = obs.coords['date']# + obs.coords['time_step']\n",
    "            basin_metrics = metrics.calculate_metrics(obs=obs, sim=sim, metrics=metrics_list)\n",
    "\n",
    "            for metric in metrics_list:\n",
    "                assimilation_statistics[metric].loc[basin, (hf, lt, en)] = basin_metrics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69b5633425c4ea599e3c72c4b17f995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CALCULATE_NEW_METRICS:\n",
    "    for run in tqdm(autoregression_holdout_run_dirs):\n",
    "        hf1 = float(run.split('_')[0])   \n",
    "        hf2 = float(run.split('_')[1])\n",
    "        en = int(run.split('_')[2])\n",
    "\n",
    "        with open(autoregression_holdout_dir + '/' + run + '/test/model_epoch030/test_results.p', 'rb') as f:\n",
    "            run_data = pkl.load(f)\n",
    "\n",
    "        for basin in basins:\n",
    "            sim = run_data[basin]['1D']['xr'].stack(datetime=['date', 'time_step'])['QObs(mm/d)_sim']\n",
    "            sim['datetime'] = sim.coords['date']# + sim.coords['time_step']\n",
    "            obs = xr[basin].stack(datetime=['date', 'time_step'])\n",
    "            obs['datetime'] = obs.coords['date']# + obs.coords['time_step']\n",
    "            basin_metrics = metrics.calculate_metrics(obs=obs, sim=sim, metrics=metrics_list)\n",
    "\n",
    "            for metric in metrics_list:\n",
    "                autoregression_fractional_holdout_statistics[metric].loc[basin, (hf1, hf2, en)] = basin_metrics[metric]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoregression_fractional_noholdout_statistics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1ac423e43642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mautoregression_holdout_statistics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mautoregression_noholdout_statistics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mautoregression_fractional_noholdout_statistics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0massimilation_statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         ], f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoregression_fractional_noholdout_statistics' is not defined"
     ]
    }
   ],
   "source": [
    "if CALCULATE_NEW_METRICS:\n",
    "    with open(filename, 'wb') as f:\n",
    "        pkl.dump([\n",
    "            simulation_statistics,\n",
    "            autoregression_holdout_statistics,\n",
    "            autoregression_noholdout_statistics,\n",
    "            autoregression_fractional_noholdout_statistics, \n",
    "            assimilation_statistics\n",
    "        ], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as f:\n",
    "    simulation_statistics, \\\n",
    "    autoregression_holdout_statistics, \\\n",
    "    autoregression_noholdout_statistics, \\\n",
    "    autoregression_fractional_noholdout_statistics, \\\n",
    "    assimilation_statistics = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregression_holdout_medians = {}\n",
    "autoregression_noholdout_medians = {}\n",
    "for metric in metrics_list:\n",
    "    autoregression_holdout_medians[metric] = pd.DataFrame(index=holdout_fractions, \n",
    "                                                          columns=lead_times,\n",
    "                                                          dtype=np.float64)\n",
    "    autoregression_noholdout_medians[metric] = pd.DataFrame(index=holdout_fractions, \n",
    "                                                            columns=lead_times,\n",
    "                                                            dtype=np.float64)\n",
    "    for hf in holdout_fractions:\n",
    "        for lt in lead_times:\n",
    "            autoregression_holdout_medians[metric].loc[hf, lt] = \\\n",
    "            autoregression_holdout_statistics[metric][(hf, lt, 0)].median()\n",
    "\n",
    "            autoregression_noholdout_medians[metric].loc[hf, lt] = \\\n",
    "            autoregression_noholdout_statistics[metric][(hf, lt, 0)].median()\n",
    "            \n",
    "assimilation_medians = {}\n",
    "for metric in metrics_list:\n",
    "    assimilation_medians[metric] = pd.DataFrame(index=holdout_fractions, \n",
    "                                                columns=lead_times,\n",
    "                                                dtype=np.float64)\n",
    "    for hf in holdout_fractions:\n",
    "        for lt in lead_times:\n",
    "            assimilation_medians[metric].loc[hf, lt] = \\\n",
    "            assimilation_statistics[metric][(hf, lt, 0)].median()\n",
    "            \n",
    "simulation_medians = {}\n",
    "for metric in metrics_list:\n",
    "    simulation_medians[metric] = pd.DataFrame(index=holdout_fractions, \n",
    "                                              columns=lead_times,\n",
    "                                              dtype=np.float64)\n",
    "    for hf in holdout_fractions:\n",
    "        for lt in lead_times:\n",
    "            simulation_medians[metric].loc[hf, lt] = \\\n",
    "            simulation_statistics[metric][(0.0, 1, 0)].median()\n",
    "\n",
    "simulation_fraction_medians = {}\n",
    "for metric in metrics_list:\n",
    "    simulation_fraction_medians[metric] = pd.DataFrame(index=holdout_fractions, \n",
    "                                                       columns=holdout_fractions,\n",
    "                                                       dtype=np.float64)\n",
    "    for hf1 in holdout_fractions:\n",
    "        for hf2 in holdout_fractions:\n",
    "            simulation_fraction_medians[metric].loc[hf1, hf2] = \\\n",
    "            simulation_statistics[metric][(0.0, 1, 0)].median()\n",
    "            \n",
    "autoregression_fractional_holdout_medians = {}\n",
    "for metric in metrics_list:\n",
    "    autoregression_fractional_holdout_medians[metric] = pd.DataFrame(index=holdout_fractions, \n",
    "                                                                     columns=holdout_fractions,\n",
    "                                                                     dtype=np.float64)\n",
    "    for hf1 in holdout_fractions:\n",
    "        for hf2 in holdout_fractions:\n",
    "            autoregression_fractional_holdout_medians[metric].loc[hf1, hf2] = \\\n",
    "            autoregression_fractional_holdout_statistics[metric][(hf1, hf2, 0)].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_medians['NSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregression_holdout_medians['NSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregression_noholdout_medians['NSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assimilation_medians['NSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregression_holdout_statistics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoregression_fractional_holdout_medians['NSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metric = 'NSE'\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "pltdata = simulation_fraction_medians[metric]\n",
    "X = pltdata.columns.values\n",
    "Y = pltdata.index.values\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax.plot_surface(X, Y, pltdata.values, label='simulation')\n",
    "\n",
    "pltdata = autoregression_fractional_holdout_medians[metric]\n",
    "X = pltdata.columns.values\n",
    "Y = pltdata.index.values\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax.plot_surface(X, Y, pltdata.values, label='autoregression with training holdout')\n",
    "\n",
    "# -------------\n",
    "metric = 'NSE'      \n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "for hf in holdout_fractions:\n",
    "    axes[0].plot(autoregression_fractional_holdout_medians[metric].loc[hf, :], label=hf)\n",
    "axes[0].plot(simulation_fraction_medians[metric].loc[hf, :], 'k--', label='Sim')\n",
    "axes[0].set_xlabel('test holdout fraction')\n",
    "axes[0].legend(title=\"train holdout fraction\", prop={'size': 6})\n",
    "axes[0].set_ylabel(metric)\n",
    "axes[0].grid()\n",
    "\n",
    "for hf in holdout_fractions:\n",
    "    axes[1].plot(autoregression_fractional_holdout_medians[metric][hf], label=hf)\n",
    "axes[1].plot(simulation_fraction_medians[metric].loc[hf, :], 'k--', label='Sim')\n",
    "axes[1].set_xlabel('train holdout fraction')\n",
    "axes[1].legend(title=\"test holdout fraction\", prop={'size': 6})\n",
    "axes[1].set_ylabel(metric)\n",
    "axes[1].grid()\n",
    "\n",
    "\n",
    "# plot_file_name = f\"./plots/{metric}_plots.png\"\n",
    "# plt.savefig(plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = 'NSE'\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "xdata = autoregression_noholdout_statistics[metric][0.000, 1, 0]\n",
    "ydata = assimilation_statistics[metric][0.000, 1, 0]\n",
    "axes[0].scatter(xdata, ydata)\n",
    "axes[0].plot([0, 1], [0, 1], 'k--')\n",
    "axes[0].set_xlabel('AR w/o Holdout')\n",
    "axes[0].set_ylabel('Variational Assimilation')\n",
    "axes[0].set_title('NSE (1-day Lag, 0% Missing Data)')\n",
    "axes[0].grid()\n",
    "\n",
    "xdata = autoregression_noholdout_statistics[metric][0.000, 1, 0]\n",
    "ydata = autoregression_holdout_statistics[metric][0.000, 1, 0]\n",
    "axes[1].scatter(xdata, ydata)\n",
    "axes[1].plot([0, 1], [0, 1], 'k--')\n",
    "axes[1].set_xlabel('AR w/o Holdout')\n",
    "axes[1].set_ylabel('AR w Holdout')\n",
    "axes[1].set_title('NSE (1-day Lag, 0% Missing Data)')\n",
    "axes[1].grid()\n",
    "\n",
    "plot_file_name = f\"./plots/scatterplot.png\"\n",
    "plt.savefig(plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'NSE'\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "pltdata = simulation_medians[metric]\n",
    "X = pltdata.columns.values\n",
    "Y = pltdata.index.values\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax.plot_surface(X, Y, pltdata.values, label='simulation')\n",
    "\n",
    "pltdata = autoregression_holdout_medians[metric]\n",
    "X = pltdata.columns.values\n",
    "Y = pltdata.index.values\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax.plot_surface(X, Y, pltdata.values, label='autoregression with training holdout')\n",
    "\n",
    "pltdata = autoregression_noholdout_medians[metric]\n",
    "X = pltdata.columns.values\n",
    "Y = pltdata.index.values\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax.plot_surface(X, Y, pltdata.values, label='autoregression without training holdout')\n",
    "\n",
    "pltdata = assimilation_medians[metric]\n",
    "X = pltdata.columns.values\n",
    "Y = pltdata.index.values\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "ax.plot_surface(X, Y, pltdata.values, label='assimilation')\n",
    "\n",
    "plot_file_name = f\"./plots/3d-surfaceplot.png\"\n",
    "plt.savefig(plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics_list:\n",
    "    \n",
    "    ymin = pd.concat((simulation_medians[metric], \n",
    "                      assimilation_medians[metric], \n",
    "                      autoregression_holdout_medians[metric], \n",
    "                      autoregression_noholdout_medians[metric])).min().min() * 0.99\n",
    "    ymax = pd.concat((simulation_medians[metric], \n",
    "                      assimilation_medians[metric], \n",
    "                      autoregression_holdout_medians[metric], \n",
    "                      autoregression_noholdout_medians[metric])).max().max()*1.01\n",
    "\n",
    "    fig, axes = plt.subplots(3,2, figsize=(8,7))\n",
    "    for i, lead_time in enumerate(lead_times):\n",
    "        axes.flatten()[i].plot(simulation_medians[metric][lead_time], label='Sim')\n",
    "        axes.flatten()[i].plot(autoregression_holdout_medians[metric][lead_time], label='AR w/ holdout')\n",
    "        axes.flatten()[i].plot(autoregression_noholdout_medians[metric][lead_time], label='AR w/o holdout')\n",
    "        axes.flatten()[i].plot(assimilation_medians[metric][lead_time], label='DA')\n",
    "        if i == 5: axes.flatten()[i].legend()\n",
    "        if i >= 4: \n",
    "            axes.flatten()[i].set_xlabel('fraction of missing data')\n",
    "        else:\n",
    "            axes.flatten()[i].set_xticks([])\n",
    "        if i%2 == 0: \n",
    "            axes.flatten()[i].set_ylabel(metric)\n",
    "        else:\n",
    "            axes.flatten()[i].set_yticks([])\n",
    "        axes.flatten()[i].set_ylim([ymin, ymax])\n",
    "        axes.flatten()[i].set_title(f'{lead_time} Days')\n",
    "        \n",
    "    plot_file_name = f\"./plots/{metric}_plots.png\"\n",
    "    plt.savefig(plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(holdout_frac, lag_time):\n",
    "    models_list = ['Simulation', 'AR w/o holdout', 'AR w/ holdout', 'Assimilation']\n",
    "    table_df = pd.DataFrame(index=metrics_list, columns=models_list)\n",
    "    for metric in metrics_list:\n",
    "        table_df.loc[metric, 'Simulation'] = simulation_medians[metric].loc[holdout_frac, lag_time]\n",
    "        table_df.loc[metric, 'AR w/o holdout'] = autoregression_noholdout_medians[metric].loc[holdout_frac, lag_time]\n",
    "        table_df.loc[metric, 'AR w/ holdout'] = autoregression_holdout_medians[metric].loc[holdout_frac, lag_time]\n",
    "        table_df.loc[metric, 'Assimilation'] = assimilation_medians[metric].loc[holdout_frac, lag_time]\n",
    "    return table_df.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplemental_table_filename = 'tables/all_metrics_tables.txt'\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "with open(supplemental_table_filename, 'wt') as f:\n",
    "    for holdout_frac in tqdm(holdout_fractions):\n",
    "        for lag_time in lead_times:\n",
    "            f.write(f'Missing Data Fraction: {holdout_frac} -- Observation Lag Time {lag_time} [days] \\n')\n",
    "            f.write(make_table(holdout_frac, lag_time))\n",
    "            f.write('\\n\\n\\n\\pagebreak \\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplemental_table_filename = 'tables/zero_lag_zero_holdout_metrics_table.txt'\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "with open(supplemental_table_filename, 'wt') as f:\n",
    "    f.write(make_table(holdout_fractions[0], lead_times[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
